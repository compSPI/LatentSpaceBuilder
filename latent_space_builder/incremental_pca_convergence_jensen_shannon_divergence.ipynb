{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(13)\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import h5py as h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2000 [00:10<36:55,  1.11s/it]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-f32707d76fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mV_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincremental_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mdata_to_project_previous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_sample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mdata_to_project_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_sample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/reg/neh/home/deebanr/.local/lib/python2.7/site-packages/h5py/_hl/dataset.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0msingle_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mmshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle_element\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# HDF5 has a bug where if the memory shape has a different rank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_name = \"3iyf-10K-mixed-hit-99\"\n",
    "h5_file = \"/reg/data/ana03/scratch/deebanr/{}/dataset/cspi_synthetic_dataset_diffraction_patterns_3iyf-10K-mixed-hit_uniform_quat_dataset-size=10000_diffraction-pattern-shape=1024x1040.hdf5\".format(dataset_name)\n",
    "h5_file_handle = h5.File(h5_file, \"r\")\n",
    "data = h5_file_handle[\"diffraction_patterns\"]\n",
    "\n",
    "total_dataset_size = 10000\n",
    "dataset_size = 10000\n",
    "batch_size = 5\n",
    "n_batches = dataset_size // batch_size \n",
    "n_latent_dims = 3\n",
    "n_iters = 10\n",
    "\n",
    "dataset_idx = np.arange(total_dataset_size)\n",
    "random_sample_idx = np.sort(np.random.choice(dataset_idx, dataset_size, replace=False))\n",
    "\n",
    "incremental_pca = IncrementalPCA(n_components=n_latent_dims)\n",
    "\n",
    "mean_previous = None\n",
    "mean_current = None\n",
    "V_previous = None\n",
    "V_current = None\n",
    "dissimilarity_measures = []\n",
    "\n",
    "for t in tqdm(range(n_batches)):\n",
    "    \n",
    "    data_batch_to_fit = data[random_sample_idx[t * batch_size : (t + 1) * batch_size]].reshape((batch_size, -1))\n",
    "    \n",
    "    incremental_pca.partial_fit(data_batch_to_fit)\n",
    "    \n",
    "    if t == 0:\n",
    "        \n",
    "        mean_previous = incremental_pca.mean_\n",
    "        V_previous = incremental_pca.components_\n",
    "    \n",
    "    elif (t + 1) % n_iters == 0:\n",
    "        \n",
    "        mean_current = incremental_pca.mean_\n",
    "        V_current = incremental_pca.components_\n",
    "        \n",
    "        data_to_project_previous = data[random_sample_idx].reshape((dataset_size, -1))\n",
    "        data_to_project_current = data[random_sample_idx].reshape((dataset_size, -1))\n",
    "        \n",
    "        projected_data_previous = np.dot(data_to_project_previous - mean_previous, V_previous.T)\n",
    "        projected_data_current = np.dot(data_to_project_current - mean_current, V_current.T)\n",
    "\n",
    "        kde_p = KernelDensity(kernel=\"gaussian\", bandwidth=0.2).fit(projected_data_previous)\n",
    "        kde_q = KernelDensity(kernel=\"gaussian\", bandwidth=0.2).fit(projected_data_current)\n",
    "\n",
    "        p = np.exp(kde_p.score_samples(projected_data_previous))\n",
    "        q = np.exp(kde_q.score_samples(projected_data_current))\n",
    "\n",
    "        dissimilarity_measures.append(distance.jensenshannon(p, q))\n",
    "        \n",
    "        mean_previous = mean_current\n",
    "        V_previous = V_current\n",
    "\n",
    "h5_file_handle.close()\n",
    "\n",
    "plt.plot(range(n_iters, n_batches + 1, n_iters), dissimilarity_measures)\n",
    "plt.ylabel(\"Jensen-Shannon Divergence\")\n",
    "plt.xlabel(\"Number of batches processed by Incremental PCA\")\n",
    "plot_title = \"Convergence of Incremental PCA on {}\\nfor a random sample of {} using a batch size of {}\".format(dataset_name, dataset_size, batch_size)\n",
    "plt.title(plot_title)\n",
    "plt.savefig(\"incremental-pca-convergence-jensen-shannon-{}-dataset_size={}-batch_size={}-n_iters={}.png\".format(dataset_name, dataset_size, batch_size, n_iters))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 ana-current",
   "language": "python",
   "name": "ana-current"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
